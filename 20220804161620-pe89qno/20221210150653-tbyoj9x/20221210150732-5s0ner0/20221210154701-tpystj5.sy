{
	"ID": "20221210154701-tpystj5",
	"Spec": "1",
	"Type": "NodeDocument",
	"Properties": {
		"id": "20221210154701-tpystj5",
		"title": "使用 Kube-vip 搭建高可用的 Kubernetes 集群(完整版)-51CTO.COM",
		"updated": "20221211020535"
	},
	"Children": [
		{
			"ID": "20221210154701-eiwdayp",
			"Type": "NodeThematicBreak",
			"Properties": {
				"id": "20221210154701-eiwdayp",
				"updated": "20221210154701"
			}
		},
		{
			"ID": "20221210154701-a0yosao",
			"Type": "NodeList",
			"ListData": {},
			"Properties": {
				"id": "20221210154701-a0yosao",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"ID": "20221210154701-mpcbges",
					"Type": "NodeListItem",
					"ListData": {
						"BulletChar": 42,
						"Marker": "Kg=="
					},
					"Properties": {
						"id": "20221210154701-mpcbges",
						"updated": "20221210154701"
					},
					"Children": [
						{
							"ID": "20221210154701-rbxy8p7",
							"Type": "NodeParagraph",
							"Properties": {
								"id": "20221210154701-rbxy8p7",
								"updated": "20221210154701"
							},
							"Children": [
								{
									"Type": "NodeTextMark",
									"TextMarkType": "a",
									"TextMarkAHref": "https://www.51cto.com/article/681443.html",
									"TextMarkTextContent": "https://www.51cto.com/article/681443.html"
								}
							]
						}
					]
				}
			]
		},
		{
			"ID": "20221210154701-6ue31vp",
			"Type": "NodeThematicBreak",
			"Properties": {
				"id": "20221210154701-6ue31vp",
				"updated": "20221210154701"
			}
		},
		{
			"ID": "20221211020504-ok5x9dd",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221211020504-ok5x9dd",
				"updated": "20221211020535"
			},
			"Children": [
				{
					"Type": "NodeTextMark",
					"TextMarkType": "a",
					"TextMarkAHref": "https://kube-vip.io/docs/about/architecture/",
					"TextMarkTextContent": "官方文档："
				}
			]
		},
		{
			"ID": "20221211020504-1z78l3m",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221211020504-1z78l3m"
			}
		},
		{
			"ID": "20221210154701-w75zynm",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-w75zynm",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "前面我们课程中的集群是单 master 的集群，对于生产环境风险太大了，非常有必要做一个高可用的集群，这里的高可用主要是针对控制面板来说的，比如  kube-apiserver、etcd、kube-controller-manager、kube-scheduler 这几个组件，其中  kube-controller-manager 于 kube-scheduler 组件是 Kubernetes  集群自己去实现的高可用，当有多个组件存在的时候，会自动选择一个作为 Leader 提供服务，所以不需要我们手动去实现高可用，apiserver 和 etcd  就需要手动去搭建高可用的集群的。高可用的架构有很多，比如典型的 haproxy + keepalived 架构，或者使用 nginx 来做代理实现。"
				}
			]
		},
		{
			"ID": "20221210154701-wckgk4a",
			"Type": "NodeHeading",
			"HeadingLevel": 3,
			"Properties": {
				"id": "20221210154701-wckgk4a",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "环境准备"
				}
			]
		},
		{
			"ID": "20221210154701-foebqwp",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-foebqwp",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "4个节点，都是 Centos 7.6 系统，内核版本：3.10.0-1062.4.1.el7.x86_64，在每个节点上添加 hosts  信息："
				}
			]
		},
		{
			"ID": "20221210154701-xa2haev",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-xa2haev",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ cat /etc/hosts \n192.168.31.10 api.k8s.local  # vip \n192.168.31.31 master1 \n192.168.31.32 master2 \n192.168.31.33 master3 \n192.168.31.100 node1 \n1.2.3.4.5.6.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-lggnxnm",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-lggnxnm",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "其中 192.168.31.10 为 vip，使用域名 api.k8s.local 进行映射。"
				}
			]
		},
		{
			"ID": "20221210154701-qzrpqrg",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-qzrpqrg",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeImage",
					"Data": "span",
					"Children": [
						{
							"Type": "NodeBang"
						},
						{
							"Type": "NodeOpenBracket"
						},
						{
							"Type": "NodeLinkText"
						},
						{
							"Type": "NodeCloseBracket"
						},
						{
							"Type": "NodeOpenParen"
						},
						{
							"Type": "NodeLinkDest",
							"Data": "https://s3.51cto.com/oss/202109/09/4d2d50a2ffa948827ed3e86443c70d0c.png"
						},
						{
							"Type": "NodeCloseParen"
						}
					]
				},
				{
					"Type": "NodeTextMark",
					"TextMarkType": "a",
					"TextMarkAHref": "https://s3.51cto.com/oss/202109/09/4d2d50a2ffa948827ed3e86443c70d0c.png",
					"TextMarkTextContent": "https://s3.51cto.com/oss/202109/09/4d2d50a2ffa948827ed3e86443c70d0c.png"
				}
			]
		},
		{
			"ID": "20221210154701-lzyzsd1",
			"Type": "NodeList",
			"ListData": {},
			"Properties": {
				"id": "20221210154701-lzyzsd1",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"ID": "20221210154701-5w4915z",
					"Type": "NodeListItem",
					"ListData": {
						"BulletChar": 42,
						"Marker": "Kg=="
					},
					"Properties": {
						"id": "20221210154701-5w4915z",
						"updated": "20221210154701"
					},
					"Children": [
						{
							"ID": "20221210154701-b4d6eq8",
							"Type": "NodeParagraph",
							"Properties": {
								"id": "20221210154701-b4d6eq8",
								"updated": "20221210154701"
							},
							"Children": [
								{
									"Type": "NodeText",
									"Data": "节点的 hostname 必须使用标准的 DNS 命名，另外千万不用什么默认的 localhost 的 hostname，会导致各种错误出现的。在  Kubernetes 项目里，机器的名字以及一切存储在 Etcd 中的 API 对象，都必须使用标准的 DNS 命名(RFC 1123)。可以使用命令  hostnamectl set-hostname node1 来修改 hostname。"
								}
							]
						}
					]
				}
			]
		},
		{
			"ID": "20221210154701-3trivks",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-3trivks",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "禁用防火墙："
				}
			]
		},
		{
			"ID": "20221210154701-msqatmd",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-msqatmd",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ systemctl stop firewalld \n➜  ~ systemctl disable firewalld \n1.2.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-xz6aykm",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-xz6aykm",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "禁用 SELINUX："
				}
			]
		},
		{
			"ID": "20221210154701-gn8u7hy",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-gn8u7hy",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ setenforce 0 \n➜  ~ cat /etc/selinux/config \nSELINUX=disabled \n1.2.3.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-dbyjybj",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-dbyjybj",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "由于开启内核 ipv4 转发需要加载 br_netfilter 模块，所以加载下该模块："
				}
			]
		},
		{
			"ID": "20221210154701-2qe4jfh",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-2qe4jfh",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ modprobe br_netfilter \n1.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-h3pziwe",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-h3pziwe",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "创建/etc/sysctl.d/k8s.conf文件，添加如下内容："
				}
			]
		},
		{
			"ID": "20221210154701-jylfyua",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-jylfyua",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "net.bridge.bridge-nf-call-ip6tables = 1 \nnet.bridge.bridge-nf-call-iptables = 1 \nnet.ipv4.ip_forward = 1 \n1.2.3.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-f8rruas",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-f8rruas",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "执行如下命令使修改生效："
				}
			]
		},
		{
			"ID": "20221210154701-kcw6ct7",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-kcw6ct7",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ sysctl -p /etc/sysctl.d/k8s.conf \n1.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-spqbrul",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-spqbrul",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "安装 ipvs："
				}
			]
		},
		{
			"ID": "20221210154701-eewoftm",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-eewoftm",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ cat \u003e /etc/sysconfig/modules/ipvs.modules \u003c\u003cEOF \n#!/bin/bash \nmodprobe -- ip_vs \nmodprobe -- ip_vs_rr \nmodprobe -- ip_vs_wrr \nmodprobe -- ip_vs_sh \nmodprobe -- nf_conntrack_ipv4 \nEOF \n➜  ~ chmod 755 /etc/sysconfig/modules/ipvs.modules \u0026\u0026 bash /etc/sysconfig/modules/ipvs.modules \u0026\u0026 lsmod | grep -e ip_vs -e nf_conntrack_ipv4 \n1.2.3.4.5.6.7.8.9.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-6h7w87o",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-6h7w87o",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "上面脚本创建了的/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。使用lsmod |  grep -e ip_vs -e nf_conntrack_ipv4命令查看是否已经正确加载所需的内核模块。"
				}
			]
		},
		{
			"ID": "20221210154701-tw8v3f0",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-tw8v3f0",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "接下来还需要确保各个节点上已经安装了 ipset 软件包："
				}
			]
		},
		{
			"ID": "20221210154701-qyg7dci",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-qyg7dci",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "为了便于查看 ipvs 的代理规则，最好安装一下管理工具 ipvsadm："
				}
			]
		},
		{
			"ID": "20221210154701-soq8ik4",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-soq8ik4",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ yum install ipvsadm \n1.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-ug7hitb",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ug7hitb",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "同步服务器时间"
				}
			]
		},
		{
			"ID": "20221210154701-qinn5yx",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-qinn5yx",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ yum install chrony -y \n➜  ~ systemctl enable chronyd \n➜  ~ systemctl start chronyd \n➜  ~ chronyc sources \n210 Number of sources = 4 \nMS Name/IP address         Stratum Poll Reach LastRx Last sample \n=============================================================================== \n^+ sv1.ggsrv.de                  2   6    17    32   -823us[-1128us] +/-   98ms \n^- montreal.ca.logiplex.net      2   6    17    32    -17ms[  -17ms] +/-  179ms \n^- ntp6.flashdance.cx            2   6    17    32    -32ms[  -32ms] +/-  161ms \n^* 119.28.183.184                2   6    33    32   +661us[ +357us] +/-   38ms \n➜  ~ date \nTue Aug 31 14:36:14 CST 2021 \n1.2.3.4.5.6.7.8.9.10.11.12.13.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-pdrxx4f",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-pdrxx4f",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "关闭 swap 分区："
				}
			]
		},
		{
			"ID": "20221210154701-5tm0d3v",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-5tm0d3v",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "修改/etc/fstab文件，注释掉 SWAP 的自动挂载，使用free -m确认 swap 已经关闭。swappiness  参数调整，修改/etc/sysctl.d/k8s.conf添加下面一行："
				}
			]
		},
		{
			"ID": "20221210154701-zws649x",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-zws649x",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "执行 sysctl -p /etc/sysctl.d/k8s.conf 使修改生效。"
				}
			]
		},
		{
			"ID": "20221210154701-n05sljt",
			"Type": "NodeHeading",
			"HeadingLevel": 3,
			"Properties": {
				"id": "20221210154701-n05sljt",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "安装 Containerd"
				}
			]
		},
		{
			"ID": "20221210154701-k20chxf",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-k20chxf",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "我们已经了解过容器运行时 containerd 的一些基本使用，接下来在各个节点上安装 Containerd。"
				}
			]
		},
		{
			"ID": "20221210154701-ou046ik",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ou046ik",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "由于 containerd 需要调用 runc，所以我们也需要先安装 runc，不过 containerd 提供了一个包含相关依赖的压缩包  cri-containerd-cni-"
				},
				{
					"Type": "NodeTextMark",
					"TextMarkType": "inline-math",
					"TextMarkInlineMathContent": "{VERSION}."
				},
				{
					"Type": "NodeText",
					"Data": "{OS}-${ARCH}.tar.gz，可以直接使用这个包来进行安装。首先从 release  页面下载最新版本的压缩包，当前为 1.5.5 版本："
				}
			]
		},
		{
			"ID": "20221210154701-gqmd079",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-gqmd079",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ wget https://github.com/containerd/containerd/releases/download/v1.5.5/cri-containerd-cni-1.5.5-linux-amd64.tar.gz \n# 如果有限制，也可以替换成下面的 URL 加速下载 \n# wget https://download.fastgit.org/containerd/containerd/releases/download/v1.5.5/cri-containerd-cni-1.5.5-linux-amd64.tar.gz \n1.2.3.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-jpo4mtr",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-jpo4mtr",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "直接将压缩包解压到系统的各个目录中："
				}
			]
		},
		{
			"ID": "20221210154701-n4o2lwf",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-n4o2lwf",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ tar -C / -xzf cri-containerd-cni-1.5.5-linux-amd64.tar.gz \n1.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-d73zbcg",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-d73zbcg",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后要将 /usr/local/bin 和 /usr/local/sbin 追加到 ~/.bashrc 文件的 PATH 环境变量中："
				}
			]
		},
		{
			"ID": "20221210154701-2fewcqe",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-2fewcqe",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "export PATH=$PATH:/usr/local/bin:/usr/local/sbin \n1.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-85b6v0c",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-85b6v0c",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后执行下面的命令使其立即生效："
				}
			]
		},
		{
			"ID": "20221210154701-y03rqir",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-y03rqir",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "containerd 的默认配置文件为 /etc/containerd/config.toml，我们可以通过如下所示的命令生成一个默认的配置："
				}
			]
		},
		{
			"ID": "20221210154701-br7vv6i",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-br7vv6i",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ mkdir -p /etc/containerd \n➜  ~ containerd config default \u003e /etc/containerd/config.toml \n1.2.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-2o6lsat",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-2o6lsat",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "对于使用 systemd 作为 init system 的 Linux 的发行版，使用 systemd 作为容器的 cgroup driver  可以确保节点在资源紧张的情况更加稳定，所以推荐将 containerd 的 cgroup driver 配置为 systemd。"
				}
			]
		},
		{
			"ID": "20221210154701-30osyt9",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-30osyt9",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "修改前面生成的配置文件 /etc/containerd/config.toml，在  plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options 配置块下面将  SystemdCgroup 设置为 true："
				}
			]
		},
		{
			"ID": "20221210154701-tu86hll",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-tu86hll",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc] \n  ... \n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options] \n    SystemdCgroup = true \n    .... \n1.2.3.4.5.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-ueli4v7",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ueli4v7",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后再为镜像仓库配置一个加速器，需要在 cri 配置块下面的 registry 配置块下面进行配置 registry.mirrors："
				}
			]
		},
		{
			"ID": "20221210154701-kxogjzo",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-kxogjzo",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "[plugins.\"io.containerd.grpc.v1.cri\"] \n  ... \n  # sandbox_image = \"k8s.gcr.io/pause:3.5\" \n  sandbox_image = \"registry.aliyuncs.com/k8sxio/pause:3.5\" \n  ... \n  [plugins.\"io.containerd.grpc.v1.cri\".registry] \n    [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors] \n      [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"] \n        endpoint = [\"https://bqr1dr1n.mirror.aliyuncs.com\"] \n      [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"k8s.gcr.io\"] \n        endpoint = [\"https://registry.aliyuncs.com/k8sxio\"] \n1.2.3.4.5.6.7.8.9.10.11.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-fn6wtos",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-fn6wtos",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "由于上面我们下载的 containerd 压缩包中包含一个 etc/systemd/system/containerd.service  的文件，这样我们就可以通过 systemd 来配置 containerd 作为守护进程运行了，现在我们就可以启动 containerd  了，直接执行下面的命令即可："
				}
			]
		},
		{
			"ID": "20221210154701-biwnsf3",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-biwnsf3",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ systemctl daemon-reload \n➜  ~ systemctl enable containerd --now \n1.2.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-1m0myor",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-1m0myor",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "启动完成后就可以使用 containerd 的本地 CLI 工具 ctr 和 crictl 了，比如查看版本："
				}
			]
		},
		{
			"ID": "20221210154701-5u3tm41",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-5u3tm41",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ ctr version \nClient: \n  Version:  v1.5.5 \n  Revision: 72cec4be58a9eb6b2910f5d10f1c01ca47d231c0 \n  Go version: go1.16.6 \n \nServer: \n  Version:  v1.5.5 \n  Revision: 72cec4be58a9eb6b2910f5d10f1c01ca47d231c0 \n  UUID: cd2894ad-fd71-4ef7-a09f-5795c7eb4c3b \n➜  ~ crictl version \nVersion:  0.1.0 \nRuntimeName:  containerd \nRuntimeVersion:  v1.5.5 \nRuntimeApiVersion:  v1alpha2 \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-355qtmb",
			"Type": "NodeHeading",
			"HeadingLevel": 3,
			"Properties": {
				"id": "20221210154701-355qtmb",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "负载均衡器"
				}
			]
		},
		{
			"ID": "20221210154701-hy80tu1",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-hy80tu1",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "为 apiserver 提供负载均衡器有很多方法，比如传统的 haproxy+keepalived，或者使用 nginx  代理也可以，这里我们使用一个比较新颖的工具 kube-vip。"
				}
			]
		},
		{
			"ID": "20221210154701-xaldpew",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-xaldpew",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "kube-vip(https://kube-vip.io/) 可以在你的控制平面节点上提供一个 Kubernetes 原生的 HA  负载均衡，我们不需要再在外部设置 HAProxy 和 Keepalived 来实现集群的高可用了。"
				}
			]
		},
		{
			"ID": "20221210154701-rtqq884",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-rtqq884",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "在以前我们在私有环境下创建 Kubernetes 集群时，我们需要准备一个硬件/软件的负载均衡器来创建多控制面集群，更多的情况下我们会选择使用  HAProxy + Keepalived 来实现这个功能。一般情况下我们创建2个负载均衡器的虚拟机，然后分配一个 VIP，然后使用 VIP  为负载均衡器提供服务，通过 VIP 将流量重定向到后端的某个 Kubernetes 控制器平面节点上。"
				}
			]
		},
		{
			"ID": "20221210154701-xcw1ywh",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-xcw1ywh",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeImage",
					"Data": "span",
					"Children": [
						{
							"Type": "NodeBang"
						},
						{
							"Type": "NodeOpenBracket"
						},
						{
							"Type": "NodeLinkText"
						},
						{
							"Type": "NodeCloseBracket"
						},
						{
							"Type": "NodeOpenParen"
						},
						{
							"Type": "NodeLinkDest",
							"Data": "https://s3.51cto.com/oss/202109/09/92276dc682e41499a2cf0e57c5dc4b16.png"
						},
						{
							"Type": "NodeCloseParen"
						}
					]
				},
				{
					"Type": "NodeTextMark",
					"TextMarkType": "a",
					"TextMarkAHref": "https://s3.51cto.com/oss/202109/09/92276dc682e41499a2cf0e57c5dc4b16.png",
					"TextMarkTextContent": "https://s3.51cto.com/oss/202109/09/92276dc682e41499a2cf0e57c5dc4b16.png"
				}
			]
		},
		{
			"ID": "20221210154701-kxy9has",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-kxy9has",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "haproxy+keepalived"
				}
			]
		},
		{
			"ID": "20221210154701-4d7r5m0",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-4d7r5m0",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "如果我们使用 kube-vip 的话会怎样呢?"
				}
			]
		},
		{
			"ID": "20221210154701-izf47rc",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-izf47rc",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeImage",
					"Data": "span",
					"Children": [
						{
							"Type": "NodeBang"
						},
						{
							"Type": "NodeOpenBracket"
						},
						{
							"Type": "NodeLinkText"
						},
						{
							"Type": "NodeCloseBracket"
						},
						{
							"Type": "NodeOpenParen"
						},
						{
							"Type": "NodeLinkDest",
							"Data": "https://s6.51cto.com/oss/202109/09/c1c1cfab275e6669d1a06b545ed6abab.png"
						},
						{
							"Type": "NodeCloseParen"
						}
					]
				},
				{
					"Type": "NodeTextMark",
					"TextMarkType": "a",
					"TextMarkAHref": "https://s6.51cto.com/oss/202109/09/c1c1cfab275e6669d1a06b545ed6abab.png",
					"TextMarkTextContent": "https://s6.51cto.com/oss/202109/09/c1c1cfab275e6669d1a06b545ed6abab.png"
				}
			]
		},
		{
			"ID": "20221210154701-fd4sjag",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-fd4sjag",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "kube-vip"
				}
			]
		},
		{
			"ID": "20221210154701-ekrpqxc",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ekrpqxc",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "kube-vip 可以通过静态 pod 运行在控制平面节点上，这些 pod 通过 ARP 会话来识别每个节点上的其他主机，我们可以选择 BGP 或 ARP  来设置负载平衡器，这与 Metal LB 比较类似。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的 Leader，而在  BGP 模式下，所有节点都会通知 VIP 地址。"
				}
			]
		},
		{
			"ID": "20221210154701-18uypq1",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-18uypq1",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "集群中的 Leader 将分配 vip，并将其绑定到配置中声明的选定接口上。当 Leader 改变时，它将首先撤销 vip，或者在失败的情况下，vip  将直接由下一个当选的 Leader 分配。当 vip 从一个主机移动到另一个主机时，任何使用 vip 的主机将保留以前的 vip \u003c-\u003e MAC  地址映射，直到 ARP 过期(通常是30秒)并检索到一个新的 vip \u003c-\u003e MAC 映射，这可以通过使用无偿的 ARP 广播来优化。"
				}
			]
		},
		{
			"ID": "20221210154701-ljyzg7n",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ljyzg7n",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "kube-vip 可以被配置为广播一个无偿的 arp(可选)，通常会立即通知所有本地主机 vip \u003c-\u003e MAC 地址映射已经改变。"
				}
			]
		},
		{
			"ID": "20221210154701-lgoemz3",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-lgoemz3",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeImage",
					"Data": "span",
					"Children": [
						{
							"Type": "NodeBang"
						},
						{
							"Type": "NodeOpenBracket"
						},
						{
							"Type": "NodeLinkText"
						},
						{
							"Type": "NodeCloseBracket"
						},
						{
							"Type": "NodeOpenParen"
						},
						{
							"Type": "NodeLinkDest",
							"Data": "https://s5.51cto.com/oss/202109/09/e1b7c3ac528aeaf602f23dfd54e14039.png"
						},
						{
							"Type": "NodeCloseParen"
						}
					]
				},
				{
					"Type": "NodeTextMark",
					"TextMarkType": "a",
					"TextMarkAHref": "https://s5.51cto.com/oss/202109/09/e1b7c3ac528aeaf602f23dfd54e14039.png",
					"TextMarkTextContent": "https://s5.51cto.com/oss/202109/09/e1b7c3ac528aeaf602f23dfd54e14039.png"
				}
			]
		},
		{
			"ID": "20221210154701-zli5lzq",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-zli5lzq",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "要使用 kube-vip 来实现集群的高可用，首先在 master1 节点上生成基本的 Kubernetes 静态 Pod 资源清单文件："
				}
			]
		},
		{
			"ID": "20221210154701-fp2mmhx",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-fp2mmhx",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ mkdir -p /etc/kubernetes/manifests/ \n# 配置vip地址 \n➜  ~ export VIP=192.168.31.10 \n# 设置网卡名称 \n➜  ~ export INTERFACE=ens33 \n➜  ~ ctr image pull docker.io/plndr/kube-vip:v0.3.8 \n# 使用下面的容器输出静态Pod资源清单 \n➜  ~ ctr run --rm --net-host docker.io/plndr/kube-vip:v0.3.8 vip \\ \n/kube-vip manifest pod \\ \n--interface $INTERFACE \\ \n--vip $VIP \\ \n--controlplane \\ \n--services \\ \n--arp \\ \n--leaderElection | tee  /etc/kubernetes/manifests/kube-vip.yaml \napiVersion: v1 \nkind: Pod \nmetadata: \n  creationTimestamp: null \n  name: kube-vip \n  namespace: kube-system \nspec: \n  containers: \n- args: \n    - manager \n    env: \n    - name: vip_arp \n      value: \"true\" \n    - name: vip_interface \n      value: ens33 \n    - name: port \n      value: \"6443\" \n    - name: vip_cidr \n      value: \"32\" \n    - name: cp_enable \n      value: \"true\" \n    - name: cp_namespace \n      value: kube-system \n    - name: vip_ddns \n      value: \"false\" \n    - name: svc_enable \n      value: \"true\" \n    - name: vip_leaderelection \n      value: \"true\" \n    - name: vip_leaseduration \n      value: \"5\" \n    - name: vip_renewdeadline \n      value: \"3\" \n    - name: vip_retryperiod \n      value: \"1\" \n    - name: vip_address \n      value: 192.168.31.10 \n    image: ghcr.io/kube-vip/kube-vip:v0.3.8 \n    imagePullPolicy: Always \n    name: kube-vip \n    resources: {} \n    securityContext: \n      capabilities: \n        add: \n        - NET_ADMIN \n        - NET_RAW \n        - SYS_TIME \n    volumeMounts: \n    - mountPath: /etc/kubernetes/admin.conf \n      name: kubeconfig \n  hostNetwork: true \n  volumes: \n- hostPath: \n      path: /etc/kubernetes/admin.conf \n    name: kubeconfig \nstatus: {} \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-ekrgrz1",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ekrgrz1",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "这里我们将 vip 设置为 192.168.31.10，首先会将 master1 节点选举为 Leader，然后接下来我们使用该 vip  来初始化控制器平台。"
				}
			]
		},
		{
			"ID": "20221210154701-k7xr42u",
			"Type": "NodeHeading",
			"HeadingLevel": 3,
			"Properties": {
				"id": "20221210154701-k7xr42u",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "初始化控制平面"
				}
			]
		},
		{
			"ID": "20221210154701-3z4zgw1",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-3z4zgw1",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "上面的相关环境配置也完成了，现在我们就可以来安装 Kubeadm 了，我们这里是通过指定 yum 源的方式来进行安装的："
				}
			]
		},
		{
			"ID": "20221210154701-st0h9pg",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-st0h9pg",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo \n[kubernetes] \nname=Kubernetes \nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 \nenabled=1 \ngpgcheck=1 \nrepo_gpgcheck=1 \ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg \n        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg \nEOF \n1.2.3.4.5.6.7.8.9.10.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-sq2skns",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-sq2skns",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "当然了，上面的 yum 源是需要科学上网的，如果不能科学上网的话，我们可以使用阿里云的源进行安装："
				}
			]
		},
		{
			"ID": "20221210154701-pqutm27",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-pqutm27",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo \n[kubernetes] \nname=Kubernetes \nbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 \nenabled=1 \ngpgcheck=0 \nrepo_gpgcheck=0 \ngpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg \n        http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg \nEOF \n1.2.3.4.5.6.7.8.9.10.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-pi1ysh1",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-pi1ysh1",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后安装 kubeadm、kubelet、kubectl："
				}
			]
		},
		{
			"ID": "20221210154701-asrelp0",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-asrelp0",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "# --disableexcludes 禁掉除了kubernetes之外的别的仓库 \n➜  ~ yum makecache fast \n➜  ~ yum install -y kubelet-1.22.1 kubeadm-1.22.1 kubectl-1.22.1 --disableexcludes=kubernetes \n➜  ~ kubeadm version \nkubeadm version: \u0026version.Info{Major:\"1\", Minor:\"22\", GitVersion:\"v1.22.1\", GitCommit:\"632ed300f2c34f6d6d15ca4cef3d3c7073412212\", GitTreeState:\"clean\", BuildDate:\"2021-08-19T15:44:22Z\", GoVersion:\"go1.16.7\", Compiler:\"gc\", Platform:\"linux/amd64\"} \n1.2.3.4.5.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-npn24ha",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-npn24ha",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "可以看到我们这里安装的是 v1.22.1 版本，然后将 master 节点的 kubelet 设置成开机启动："
				}
			]
		},
		{
			"ID": "20221210154701-3c5mnov",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-3c5mnov",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ systemctl enable --now kubelet \n1.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-3pahxqu",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-3pahxqu",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "到这里为止上面所有的操作都需要在所有节点执行配置。"
				}
			]
		},
		{
			"ID": "20221210154701-ux4qrjk",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ux4qrjk",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "当我们执行 kubelet --help 命令的时候可以看到原来大部分命令行参数都被 DEPRECATED了，这是因为官方推荐我们使用 --config  来指定配置文件，在配置文件中指定原来这些参数的配置，可以通过官方文档 Set Kubelet parameters via a config file  了解更多相关信息，这样 Kubernetes 就可以支持动态 Kubelet 配置(Dynamic Kubelet Configuration)了，参考  Reconfigure a Node’s Kubelet in a Live Cluster。"
				}
			]
		},
		{
			"ID": "20221210154701-tah6xki",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-tah6xki",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后我们可以通过下面的命令在 master1 节点上输出集群初始化默认使用的配置："
				}
			]
		},
		{
			"ID": "20221210154701-7cl4xui",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-7cl4xui",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubeadm config print init-defaults --component-configs KubeletConfiguration \u003e kubeadm.yaml \n1.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-290bwl5",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-290bwl5",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后根据我们自己的需求修改配置，比如修改 imageRepository 指定集群初始化时拉取 Kubernetes 所需镜像的地址，kube-proxy  的模式为 ipvs，另外需要注意的是我们这里是准备安装 flannel 网络插件的，需要将 networking.podSubnet  设置为10.244.0.0/16："
				}
			]
		},
		{
			"ID": "20221210154701-prt11fi",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-prt11fi",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "# kubeadm.yaml \napiVersion: kubeadm.k8s.io/v1beta3 \nbootstrapTokens: \n- groups: \n  - system:bootstrappers:kubeadm:default-node-token \n  token: abcdef.0123456789abcdef \n  ttl: 24h0m0s \n  usages: \n  - signing \n  - authentication \nkind: InitConfiguration \nlocalAPIEndpoint: \n  advertiseAddress: 192.168.31.31  # 指定当前节点内网IP \n  bindPort: 6443 \nnodeRegistration: \n  criSocket: /run/containerd/containerd.sock  # 使用 containerd的Unix socket 地址 \n  imagePullPolicy: IfNotPresent \n  name: master1 \n  taints:  # 给master添加污点，master节点不能调度应用 \n  - effect: \"NoSchedule\" \n    key: \"node-role.kubernetes.io/master\" \n--- \napiVersion: kubeproxy.config.k8s.io/v1alpha1 \nkind: KubeProxyConfiguration \nmode: ipvs  # kube-proxy 模式 \n--- \napiVersion: kubeadm.k8s.io/v1beta3 \ncertificatesDir: /etc/kubernetes/pki \nclusterName: kubernetes \ncontrollerManager: {} \ndns: {} \netcd: \n  local: \n    dataDir: /var/lib/etcd \nimageRepository: registry.aliyuncs.com/k8sxio \nkind: ClusterConfiguration \nkubernetesVersion: 1.22.1 \ncontrolPlaneEndpoint: api.k8s.local:6443  # 设置控制平面Endpoint地址 \napiServer: \n  extraArgs: \n    authorization-mode: Node,RBAC \n  timeoutForControlPlane: 4m0s \n  certSANs:  # 添加其他master节点的相关信息 \n  - api.k8s.local \n  - master1 \n  - master2 \n  - master3 \n  - 192.168.31.30 \n  - 192.168.31.31 \n  - 192.168.31.32 \nnetworking: \n  dnsDomain: cluster.local \n  serviceSubnet: 10.96.0.0/12 \n  podSubnet: 10.244.0.0/16  # 指定 pod 子网 \nscheduler: {} \n--- \napiVersion: kubelet.config.k8s.io/v1beta1 \nauthentication: \n  anonymous: \n    enabled: false \n  webhook: \n    cacheTTL: 0s \n    enabled: true \n  x509: \n    clientCAFile: /etc/kubernetes/pki/ca.crt \nauthorization: \n  mode: Webhook \n  webhook: \n    cacheAuthorizedTTL: 0s \n    cacheUnauthorizedTTL: 0s \nclusterDNS: \n- 10.96.0.10 \nclusterDomain: cluster.local \ncpuManagerReconcilePeriod: 0s \nevictionPressureTransitionPeriod: 0s \nfileCheckFrequency: 0s \nhealthzBindAddress: 127.0.0.1 \nhealthzPort: 10248 \nhttpCheckFrequency: 0s \nimageMinimumGCAge: 0s \nkind: KubeletConfiguration \ncgroupDriver: systemd  # 配置 cgroup driver \nlogging: {} \nmemorySwap: {} \nnodeStatusReportFrequency: 0s \nnodeStatusUpdateFrequency: 0s \nrotateCertificates: true \nruntimeRequestTimeout: 0s \nshutdownGracePeriod: 0s \nshutdownGracePeriodCriticalPods: 0s \nstaticPodPath: /etc/kubernetes/manifests \nstreamingConnectionIdleTimeout: 0s \nsyncFrequency: 0s \nvolumeStatsAggPeriod: 0s \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.37.38.39.40.41.42.43.44.45.46.47.48.49.50.51.52.53.54.55.56.57.58.59.60.61.62.63.64.65.66.67.68.69.70.71.72.73.74.75.76.77.78.79.80.81.82.83.84.85.86.87.88.89.90.91.92.93.94.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-q4oxetg",
			"Type": "NodeList",
			"ListData": {},
			"Properties": {
				"id": "20221210154701-q4oxetg",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"ID": "20221210154701-iuv9c41",
					"Type": "NodeListItem",
					"ListData": {
						"BulletChar": 42,
						"Marker": "Kg=="
					},
					"Properties": {
						"id": "20221210154701-iuv9c41",
						"updated": "20221210154701"
					},
					"Children": [
						{
							"ID": "20221210154701-h97mci3",
							"Type": "NodeParagraph",
							"Properties": {
								"id": "20221210154701-h97mci3",
								"updated": "20221210154701"
							},
							"Children": [
								{
									"Type": "NodeText",
									"Data": "对于上面的资源清单的文档比较杂，要想完整了解上面的资源对象对应的属性，可以查看对应的 godoc 文档，地址:  https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta3。"
								}
							]
						}
					]
				}
			]
		},
		{
			"ID": "20221210154701-x20yhxs",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-x20yhxs",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "这里需要注意的是我们在 ClusterConfiguration 块的配置中新增了控制平面的地址以及将 api.k8s.local  这个域名加入到了证书签名中，该域名将映射到 vip："
				}
			]
		},
		{
			"ID": "20221210154701-sy9k3ug",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-sy9k3ug",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "controlPlaneEndpoint: api.k8s.local:6443  # 设置控制平面Endpoint地址 \napiServer: \n  extraArgs: \n    authorization-mode: Node,RBAC \n  timeoutForControlPlane: 4m0s \n  certSANs:  # 添加其他master节点的相关信息 \n  - api.k8s.local \n  - master1 \n  - master2 \n  - master3 \n  - 192.168.31.30 \n  - 192.168.31.31 \n  - 192.168.31.32 \n1.2.3.4.5.6.7.8.9.10.11.12.13.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-t6i2ilt",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-t6i2ilt",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "在开始初始化集群之前可以使用 kubeadm config images pull --config kubeadm.yaml  预先在各个服务器节点上拉取所k8s需要的容器镜像。"
				}
			]
		},
		{
			"ID": "20221210154701-gb4p8zy",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-gb4p8zy",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "配置文件准备好过后，可以使用如下命令先将相关镜像 pull 下面："
				}
			]
		},
		{
			"ID": "20221210154701-kufgyq4",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-kufgyq4",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubeadm config images pull --config kubeadm.yaml \n[config/images] Pulled registry.aliyuncs.com/k8sxio/kube-apiserver:v1.22.1 \n[config/images] Pulled registry.aliyuncs.com/k8sxio/kube-controller-manager:v1.22.1 \n[config/images] Pulled registry.aliyuncs.com/k8sxio/kube-scheduler:v1.22.1 \n[config/images] Pulled registry.aliyuncs.com/k8sxio/kube-proxy:v1.22.1 \n[config/images] Pulled registry.aliyuncs.com/k8sxio/pause:3.5 \n[config/images] Pulled registry.aliyuncs.com/k8sxio/etcd:3.5.0-0 \nfailed to pull image \"registry.aliyuncs.com/k8sxio/coredns:v1.8.4\": output: time=\"2021-08-31T15:09:13+08:00\" level=fatal msg=\"pulling image: rpc error: code = NotFound desc = failed to pull and unpack image \\\"registry.aliyuncs.com/k8sxio/coredns:v1.8.4\\\": failed to resolve reference \\\"registry.aliyuncs.com/k8sxio/coredns:v1.8.4\\\": registry.aliyuncs.com/k8sxio/coredns:v1.8.4: not found\" \n, error: exit status 1 \nTo see the stack trace of this error execute with --v=5 or higher \n1.2.3.4.5.6.7.8.9.10.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-1z86e6k",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-1z86e6k",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "上面在拉取 coredns 镜像的时候出错了，没有找到这个镜像，我们可以手动 pull 该镜像，然后重新 tag 下镜像地址即可："
				}
			]
		},
		{
			"ID": "20221210154701-urw1u8q",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-urw1u8q",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ ctr -n k8s.io i pull docker.io/coredns/coredns:1.8.4 \n➜  ~ ctr -n k8s.io i tag docker.io/coredns/coredns:1.8.4 registry.aliyuncs.com/k8sxio/coredns:v1.8.4 \n1.2.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-205m8yi",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-205m8yi",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后就可以使用上面的配置文件在 master1 节点上进行初始化："
				}
			]
		},
		{
			"ID": "20221210154701-qxmyqq2",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-qxmyqq2",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubeadm init --upload-certs --config kubeadm.yaml \n[init] Using Kubernetes version: v1.22.1 \n[preflight] Running pre-flight checks \n[preflight] Pulling images required for setting up a Kubernetes cluster \n...... \n \nYour Kubernetes control-plane has initialized successfully! \n \nTo start using your cluster, you need to run the following as a regular user: \n \n  mkdir -p $HOME/.kube \n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config \n  sudo chown $(id -u):$(id -g) $HOME/.kube/config \n \nAlternatively, if you are the root user, you can run: \n \n  export KUBECONFIG=/etc/kubernetes/admin.conf \n \nYou should now deploy a pod network to the cluster. \nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: \n  https://kubernetes.io/docs/concepts/cluster-administration/addons/ \n \nYou can now join any number of the control-plane node running the following command on each as root: \n \n  kubeadm join api.k8s.local:6443 --token abcdef.0123456789abcdef \\ \n --discovery-token-ca-cert-hash sha256:435fbc28490d1f897337923c19ec27bcf3639e9fe84e8448177777d23cae4176 \\ \n --control-plane --certificate-key 7892cd62c5ab60b28b462af32c7e49aa73d5fd4f723352f3af6546a74e465abc \n \nPlease note that the certificate-key gives access to cluster sensitive data, keep it secret! \nAs a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use \n\"kubeadm init phase upload-certs --upload-certs\" to reload certs afterward. \n \nThen you can join any number of worker nodes by running the following on each as root: \n \nkubeadm join api.k8s.local:6443 --token abcdef.0123456789abcdef \\ \n --discovery-token-ca-cert-hash sha256:435fbc28490d1f897337923c19ec27bcf3639e9fe84e8448177777d23cae4176 \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.34.35.36.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-xmukkpu",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-xmukkpu",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "这里初始化的 --upload-certs 标志用来将在所有控制平面实例之间的共享证书上传到集群。然后根据安装提示拷贝 kubeconfig  文件："
				}
			]
		},
		{
			"ID": "20221210154701-fsdy486",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-fsdy486",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ mkdir -p $HOME/.kube \n➜  ~ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config \n➜  ~ sudo chown $(id -u):$(id -g) $HOME/.kube/config \n1.2.3.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-93gsosn",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-93gsosn",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "接着我们可以根据上面的提示添加其他的控制平面节点。"
				}
			]
		},
		{
			"ID": "20221210154701-8pb8jgz",
			"Type": "NodeHeading",
			"HeadingLevel": 3,
			"Properties": {
				"id": "20221210154701-8pb8jgz",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "添加控制平面"
				}
			]
		},
		{
			"ID": "20221210154701-zo0uqju",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-zo0uqju",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "对于每个其他控制平面节点，执行先前在第一个节点 master1 上的 kubeadm init 输出提供的 join  命令来添加控制平面节点："
				}
			]
		},
		{
			"ID": "20221210154701-vt44ny6",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-vt44ny6",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubeadm join api.k8s.local:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:435fbc28490d1f897337923c19ec27bcf3639e9fe84e8448177777d23cae4176 --control-plane --certificate-key 7892cd62c5ab60b28b462af32c7e49aa73d5fd4f723352f3af6546a74e465abc \n[preflight] Running pre-flight checks \n[preflight] Reading configuration from the cluster... \n[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml' \n[preflight] Running pre-flight checks before initializing the new control plane instance \n...... \nThis node has joined the cluster and a new control plane instance was created: \n \n* Certificate signing request was sent to apiserver and approval was received. \n* The Kubelet was informed of the new secure connection details. \n* Control plane (master) label and taint were applied to the new node. \n* The Kubernetes control plane instances scaled up. \n* A new etcd member was added to the local/stacked etcd cluster. \n \nTo start administering your cluster from this node, you need to run the following as a regular user: \n \n mkdir -p $HOME/.kube \n sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config \n sudo chown $(id -u):$(id -g) $HOME/.kube/config \n \nRun 'kubectl get nodes' to see this node join the cluster. \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-blwz33q",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-blwz33q",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "需要注意需要在另外两个节点 master2 和 master3 都执行上面的 join 命令，上面的命令中的 --control-plane 就是通知  kubeadm join 创建一个新的控制平面，--certificate-key 会从集群中的 kubeadm-certs Secret  下载控制平面证书并使用给定的密钥进行解密。"
				}
			]
		},
		{
			"ID": "20221210154701-ftr6uui",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ftr6uui",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "当这两个节点被添加到集群后，我们接下来也需要在节点上运行 kube-vip，将当前节点作为 kube-vip 的成员，同样执行下面的命令即可："
				}
			]
		},
		{
			"ID": "20221210154701-9tmh604",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-9tmh604",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "# 配置vip地址 \n➜  ~ export VIP=192.168.31.10 \n# 设置网卡名称 \n➜  ~ export INTERFACE=ens33 \n➜  ~ ctr image pull docker.io/plndr/kube-vip:v0.3.8 \n# 使用下面的容器输出静态Pod资源清单 \n➜  ~ ctr run --rm --net-host docker.io/plndr/kube-vip:v0.3.8 vip \\ \n/kube-vip manifest pod \\ \n--interface $INTERFACE \\ \n--vip $VIP \\ \n--controlplane \\ \n--services \\ \n--arp \\ \n--leaderElection | tee  /etc/kubernetes/manifests/kube-vip.yaml \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-6qezt7w",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-6qezt7w",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "当 kube-vip 的静态 Pod 清单创建完成后，正常将能够看到 kube-vip 的 Pod 会按预期启动并运行："
				}
			]
		},
		{
			"ID": "20221210154701-ea6r5pv",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-ea6r5pv",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl get pods -A | grep vip \nkube-system   kube-vip-master1                  1/1     Running             1                7m42s \nkube-system   kube-vip-master2                  1/1     Running             0                4m24s \nkube-system   kube-vip-master3                  1/1     Running             0                14s \n1.2.3.4.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-rvqm33v",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-rvqm33v",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "这个时候控制平面节点就都准备好了："
				}
			]
		},
		{
			"ID": "20221210154701-chrwqa3",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-chrwqa3",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl get nodes \nNAME      STATUS   ROLES                  AGE     VERSION \nmaster1   Ready    control-plane,master   9m18s   v1.22.1 \nmaster2   Ready    control-plane,master   7m11s   v1.22.1 \nmaster3   Ready    control-plane,master   5m9s    v1.22.1 \n1.2.3.4.5.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-63zahkp",
			"Type": "NodeHeading",
			"HeadingLevel": 3,
			"Properties": {
				"id": "20221210154701-63zahkp",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "添加工作节点"
				}
			]
		},
		{
			"ID": "20221210154701-z1lk7hm",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-z1lk7hm",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "接下来我们可以将 node1 工作节点加入到集群中，同样使用在 master1 上初始化后的提示 join 命令，记得将 master1  节点上面的 $HOME/.kube/config 文件拷贝到 node 节点对应的文件中，安装  kubeadm、kubelet、kubectl(可选)，然后执行上面初始化完成后提示的 join 命令即可："
				}
			]
		},
		{
			"ID": "20221210154701-fo61224",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-fo61224",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubeadm join api.k8s.local:6443 --token abcdef.0123456789abcdef \\ \n\u003e --discovery-token-ca-cert-hash sha256:435fbc28490d1f897337923c19ec27bcf3639e9fe84e8448177777d23cae4176 \n[preflight] Running pre-flight checks \n[preflight] Reading configuration from the cluster... \n[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml' \n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" \n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" \n[kubelet-start] Starting the kubelet \n[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... \n \nThis node has joined the cluster: \n* Certificate signing request was sent to apiserver and a response was received. \n* The Kubelet was informed of the new secure connection details. \n \nRun 'kubectl get nodes' on the control-plane to see this node join the cluster. \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-pd1qenv",
			"Type": "NodeList",
			"ListData": {},
			"Properties": {
				"id": "20221210154701-pd1qenv",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"ID": "20221210154701-eo5lxpw",
					"Type": "NodeListItem",
					"ListData": {
						"BulletChar": 42,
						"Marker": "Kg=="
					},
					"Properties": {
						"id": "20221210154701-eo5lxpw",
						"updated": "20221210154701"
					},
					"Children": [
						{
							"ID": "20221210154701-4s4esjw",
							"Type": "NodeParagraph",
							"Properties": {
								"id": "20221210154701-4s4esjw",
								"updated": "20221210154701"
							},
							"Children": [
								{
									"Type": "NodeText",
									"Data": "如果忘记了上面的 join 命令可以使用命令 kubeadm token create --print-join-command 重新获取。"
								}
							]
						}
					]
				}
			]
		},
		{
			"ID": "20221210154701-bgkg0gv",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-bgkg0gv",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "执行成功后运行 get nodes 命令："
				}
			]
		},
		{
			"ID": "20221210154701-q7fow9n",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-q7fow9n",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl get nodes \nNAME      STATUS   ROLES                  AGE     VERSION \nmaster1   Ready    control-plane,master   9m18s   v1.22.1 \nmaster2   Ready    control-plane,master   7m11s   v1.22.1 \nmaster3   Ready    control-plane,master   5m9s    v1.22.1 \nnode1     NotReady \u003cnone\u003e                 24s     v1.22.1 \n1.2.3.4.5.6.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-1wwllej",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-1wwllej",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "可以看到是 NotReady 状态，这是因为还没有安装网络插件，接下来安装网络插件，可以在文档  https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/  中选择我们自己的网络插件，这里我们安装 flannel:"
				}
			]
		},
		{
			"ID": "20221210154701-hq0ar4e",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-hq0ar4e",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml \n# 如果有节点是多网卡，则需要在资源清单文件中指定内网网卡 \n# 搜索到名为 kube-flannel-ds 的 DaemonSet，在kube-flannel容器下面 \n➜  ~ vi kube-flannel.yml \n...... \ncontainers: \n- name: kube-flannel \n  image: quay.io/coreos/flannel:v0.14.0 \n  command: \n  - /opt/bin/flanneld \n  args: \n  - --ip-masq \n  - --kube-subnet-mgr \n  - --iface=eth0  # 如果是多网卡的话，指定内网网卡的名称 \n...... \n➜  ~ kubectl apply -f kube-flannel.yml  # 安装 flannel 网络插件 \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-lcdci2e",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-lcdci2e",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "隔一会儿查看 Pod 运行状态："
				}
			]
		},
		{
			"ID": "20221210154701-748kt8n",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-748kt8n",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl get pods -n kube-system \nNAME                              READY   STATUS    RESTARTS       AGE \ncoredns-7568f67dbd-lvcd5          1/1     Running   0              30m \ncoredns-7568f67dbd-shfrk          1/1     Running   0              30m \netcd-master1                      1/1     Running   0              45m \netcd-master2                      1/1     Running   0              45m \netcd-master3                      1/1     Running   1 (46m ago)    54m \nkube-apiserver-master1            1/1     Running   4 (45m ago)    58m \nkube-apiserver-master2            1/1     Running   2 (45m ago)    56m \nkube-apiserver-master3            1/1     Running   1 (46m ago)    54m \nkube-controller-manager-master1   1/1     Running   15 (48m ago)   58m \nkube-controller-manager-master2   1/1     Running   1 (47m ago)    56m \nkube-controller-manager-master3   1/1     Running   0              54m \nkube-flannel-ds-4js7f             1/1     Running   0              38m \nkube-flannel-ds-hch26             1/1     Running   0              38m \nkube-flannel-ds-l6xzv             1/1     Running   0              38m \nkube-flannel-ds-qpzqq             1/1     Running   0              38m \nkube-proxy-fpxp8                  1/1     Running   0              54m \nkube-proxy-qdsfq                  1/1     Running   0              56m \nkube-proxy-ww9b2                  1/1     Running   0              58m \nkube-proxy-zcw98                  1/1     Running   0              50m \nkube-scheduler-master1            1/1     Running   15 (48m ago)   58m \nkube-scheduler-master2            1/1     Running   0              56m \nkube-scheduler-master3            1/1     Running   1 (47m ago)    54m \nkube-vip-master1                  1/1     Running   2 (48m ago)    58m \nkube-vip-master2                  1/1     Running   1 (47m ago)    55m \nkube-vip-master3                  1/1     Running   0              51m \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-smslkx8",
			"Type": "NodeList",
			"ListData": {},
			"Properties": {
				"id": "20221210154701-smslkx8",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"ID": "20221210154701-ea68npr",
					"Type": "NodeListItem",
					"ListData": {
						"BulletChar": 42,
						"Marker": "Kg=="
					},
					"Properties": {
						"id": "20221210154701-ea68npr",
						"updated": "20221210154701"
					},
					"Children": [
						{
							"ID": "20221210154701-2vwdwlb",
							"Type": "NodeParagraph",
							"Properties": {
								"id": "20221210154701-2vwdwlb",
								"updated": "20221210154701"
							},
							"Children": [
								{
									"Type": "NodeText",
									"Data": "当我们部署完网络插件后执行 ifconfig  命令，正常会看到新增的cni0与flannel1这两个虚拟设备，但是如果没有看到cni0这个设备也不用太担心，我们可以观察/var/lib/cni目录是否存在，如果不存在并不是说部署有问题，而是该节点上暂时还没有应用运行，我们只需要在该节点上运行一个  Pod 就可以看到该目录会被创建，并且cni0设备也会被创建出来。"
								}
							]
						}
					]
				}
			]
		},
		{
			"ID": "20221210154701-sc7yig5",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-sc7yig5",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "网络插件运行成功了，node 状态也正常了："
				}
			]
		},
		{
			"ID": "20221210154701-gl5as1y",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-gl5as1y",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl get nodes \nNAME      STATUS   ROLES                  AGE     VERSION \nmaster1   Ready    control-plane,master   9m18s   v1.22.1 \nmaster2   Ready    control-plane,master   7m11s   v1.22.1 \nmaster3   Ready    control-plane,master   5m9s    v1.22.1 \nnode1     Ready    \u003cnone\u003e                 24s     v1.22.1 \n1.2.3.4.5.6.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-j7vut3v",
			"Type": "NodeHeading",
			"HeadingLevel": 3,
			"Properties": {
				"id": "20221210154701-j7vut3v",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "测试高可用"
				}
			]
		},
		{
			"ID": "20221210154701-c3j69bd",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-c3j69bd",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "上面我们搭建了3个 master 节点的高可用 Kubernetes 集群，接下来我们来测试下高可用是否生效。"
				}
			]
		},
		{
			"ID": "20221210154701-cab131p",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-cab131p",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "首先查看其中任一个 kube-vip 的 Pod 日志："
				}
			]
		},
		{
			"ID": "20221210154701-m3r3pml",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-m3r3pml",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl logs -f kube-vip-master1 -n kube-system \ntime=\"2021-09-07T08:53:24Z\" level=info msg=\"server started\" \ntime=\"2021-09-07T08:53:24Z\" level=info msg=\"Starting Kube-vip Manager with the ARP engine\" \ntime=\"2021-09-07T08:53:24Z\" level=info msg=\"Namespace [kube-system], Hybrid mode [true]\" \ntime=\"2021-09-07T08:53:24Z\" level=info msg=\"Beginning cluster membership, namespace [kube-system], lock name [plndr-svcs-lock], id [master1]\" \nI0907 08:53:24.205669       1 leaderelection.go:243] attempting to acquire leader lease kube-system/plndr-svcs-lock... \ntime=\"2021-09-07T08:53:24Z\" level=info msg=\"Beginning cluster membership, namespace [kube-system], lock name [plndr-cp-lock], id [master1]\" \nI0907 08:53:24.206162       1 leaderelection.go:243] attempting to acquire leader lease  kube-system/plndr-cp-lock... \n...... \ntime=\"2021-09-07T08:55:55Z\" level=info msg=\"Node [master3] is assuming leadership of the cluster\" \ntime=\"2021-09-07T08:55:55Z\" level=info msg=\"new leader elected: master3\" \n1.2.3.4.5.6.7.8.9.10.11.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-y80j2jp",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-y80j2jp",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "可以看到 master3 现在是我们的 Leader，接下来我们将 master3 节点关掉，然后观察另外的 kube-vip 的日志变化："
				}
			]
		},
		{
			"ID": "20221210154701-iopfqo4",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-iopfqo4",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl logs -f kube-vip-master2 -n kube-system \n...... \ntime=\"2021-09-07T08:55:55Z\" level=info msg=\"Node [master3] is assuming leadership of the cluster\" \ntime=\"2021-09-07T08:55:55Z\" level=info msg=\"new leader elected: master3\" \ntime=\"2021-09-07T10:28:58Z\" level=info msg=\"Node [master1] is assuming leadership of the cluster\" \n...... \n1.2.3.4.5.6.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-erc5vsm",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-erc5vsm",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "可以看到 master1 节点获取了 kube-vip 的 Leader，也就是这个时候 vip 是绑定到 master1  节点的，而且这个时候集群仍然可以正常访问的。"
				}
			]
		},
		{
			"ID": "20221210154701-e0uj3zf",
			"Type": "NodeHeading",
			"HeadingLevel": 3,
			"Properties": {
				"id": "20221210154701-e0uj3zf",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "Dashboard"
				}
			]
		},
		{
			"ID": "20221210154701-62e2uhh",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-62e2uhh",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "v1.22.1 版本的集群需要安装最新的 2.0+ 版本的 Dashboard："
				}
			]
		},
		{
			"ID": "20221210154701-gju5ox2",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-gju5ox2",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "# 推荐使用下面这种方式 \n➜  ~ wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml \n➜  ~ vi recommended.yaml \n# 修改Service为NodePort类型 \n...... \nkind: Service \napiVersion: v1 \nmetadata: \n  labels: \n    k8s-app: kubernetes-dashboard \n  name: kubernetes-dashboard \n  namespace: kubernetes-dashboard \nspec: \n  ports: \n    - port: 443 \n      targetPort: 8443 \n  selector: \n    k8s-app: kubernetes-dashboard \n  type: NodePort  # 加上type=NodePort变成NodePort类型的服务 \n...... \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-4a992qn",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-4a992qn",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "直接创建："
				}
			]
		},
		{
			"ID": "20221210154701-pb4lifx",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-pb4lifx",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl apply -f recommended.yaml \n1.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-9z3nzuk",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-9z3nzuk",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "新版本的 Dashboard 会被默认安装在 kubernetes-dashboard 这个命名空间下面："
				}
			]
		},
		{
			"ID": "20221210154701-mpf7mtv",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-mpf7mtv",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl get pods -n kubernetes-dashboard -o wide \nNAME                                         READY   STATUS    RESTARTS   AGE   IP          NODE     NOMINATED NODE   READINESS GATES \ndashboard-metrics-scraper-856586f554-pllvt   1/1     Running   0          24m   10.88.0.7   master   \u003cnone\u003e           \u003cnone\u003e \nkubernetes-dashboard-76597d7df5-82998        1/1     Running   0          21m   10.88.0.2   node2    \u003cnone\u003e           \u003cnone\u003e \n1.2.3.4.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-v3add8c",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-v3add8c",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "我们仔细看可以发现上面的 Pod 分配的 IP 段是 10.88.xx.xx，包括前面自动安装的 CoreDNS 也是如此，我们前面不是配置的  podSubnet 为 10.244.0.0/16 吗?我们先去查看下 CNI 的配置文件："
				}
			]
		},
		{
			"ID": "20221210154701-q1ppnev",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-q1ppnev",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ ls -la /etc/cni/net.d/ \ntotal 8 \ndrwxr-xr-x  2 1001 docker  67 Aug 31 16:45 . \ndrwxr-xr-x. 3 1001 docker  19 Jul 30 01:13 .. \n-rw-r--r--  1 1001 docker 604 Jul 30 01:13 10-containerd-net.conflist \n-rw-r--r--  1 root root   292 Aug 31 16:45 10-flannel.conflist \n1.2.3.4.5.6.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-5dwzu81",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-5dwzu81",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "可以看到里面包含两个配置，一个是 10-containerd-net.conflist，另外一个是我们上面创建的 Flannel  网络插件生成的配置，我们的需求肯定是想使用 Flannel 的这个配置，我们可以查看下 containerd 这个自带的 cni 插件配置："
				}
			]
		},
		{
			"ID": "20221210154701-mivslrf",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-mivslrf",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ cat /etc/cni/net.d/10-containerd-net.conflist \n{ \n  \"cniVersion\": \"0.4.0\", \n  \"name\": \"containerd-net\", \n  \"plugins\": [ \n    { \n      \"type\": \"bridge\", \n      \"bridge\": \"cni0\", \n      \"isGateway\": true, \n      \"ipMasq\": true, \n      \"promiscMode\": true, \n      \"ipam\": { \n        \"type\": \"host-local\", \n        \"ranges\": [ \n          [{ \n            \"subnet\": \"10.88.0.0/16\" \n          }], \n          [{ \n            \"subnet\": \"2001:4860:4860::/64\" \n          }] \n        ], \n        \"routes\": [ \n          { \"dst\": \"0.0.0.0/0\" }, \n          { \"dst\": \"::/0\" } \n        ] \n      } \n    }, \n    { \n      \"type\": \"portmap\", \n      \"capabilities\": {\"portMappings\": true} \n    } \n  ] \n} \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.20.21.22.23.24.25.26.27.28.29.30.31.32.33.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-uzr7mxz",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-uzr7mxz",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "可以看到上面的 IP 段恰好就是 10.88.0.0/16，但是这个 cni 插件类型是 bridge 网络，网桥的名称为 cni0："
				}
			]
		},
		{
			"ID": "20221210154701-0dh28x3",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-0dh28x3",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ ip a \n... \n6: cni0: \u003cBROADCAST,MULTICAST,PROMISC,UP,LOWER_UP\u003e mtu 1500 qdisc noqueue state UP group default qlen 1000 \n    link/ether 9a:e7:eb:40:e8:66 brd ff:ff:ff:ff:ff:ff \n    inet 10.88.0.1/16 brd 10.88.255.255 scope global cni0 \n       valid_lft forever preferred_lft forever \n    inet6 2001:4860:4860::1/64 scope global \n       valid_lft forever preferred_lft forever \n    inet6 fe80::98e7:ebff:fe40:e866/64 scope link \n       valid_lft forever preferred_lft forever \n... \n1.2.3.4.5.6.7.8.9.10.11.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-3mcyoue",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-3mcyoue",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "但是使用 bridge 网络的容器无法跨多个宿主机进行通信，跨主机通信需要借助其他的 cni 插件，比如上面我们安装的 Flannel，或者 Calico  等等，由于我们这里有两个 cni 配置，所以我们需要将 10-containerd-net.conflist 这个配置删除，因为如果这个目录中有多个 cni  配置文件，kubelet 将会使用按文件名的字典顺序排列的第一个作为配置文件，所以前面默认选择使用的是 containerd-net 这个插件。"
				}
			]
		},
		{
			"ID": "20221210154701-11veszz",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-11veszz",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ mv /etc/cni/net.d/10-containerd-net.conflist /etc/cni/net.d/10-containerd-net.conflist.bak \n➜  ~ ifconfig cni0 down \u0026\u0026 ip link delete cni0 \n➜  ~ systemctl daemon-reload \n➜  ~ systemctl restart containerd kubelet \n1.2.3.4.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-vue3lyz",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-vue3lyz",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后记得重建 coredns 和 dashboard 的 Pod，重建后 Pod 的 IP 地址就正常了："
				}
			]
		},
		{
			"ID": "20221210154701-9zn9gi9",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-9zn9gi9",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl get pods -n kubernetes-dashboard -o wide \nNAME                                         READY   STATUS    RESTARTS   AGE   IP           NODE    NOMINATED NODE   READINESS GATES \ndashboard-metrics-scraper-856586f554-tp8m5   1/1     Running   0          42s   10.244.1.6   node2   \u003cnone\u003e           \u003cnone\u003e \nkubernetes-dashboard-76597d7df5-9rmbx        1/1     Running   0          66s   10.244.1.5   node2   \u003cnone\u003e           \u003cnone\u003e \n➜  ~ kubectl get pods -n kube-system -o wide -l k8s-app=kube-dns \nNAME                       READY   STATUS    RESTARTS   AGE     IP           NODE    NOMINATED NODE   READINESS GATES \ncoredns-7568f67dbd-n7bfx   1/1     Running   0          5m40s   10.244.1.2   node2   \u003cnone\u003e           \u003cnone\u003e \ncoredns-7568f67dbd-plrv8   1/1     Running   0          3m47s   10.244.1.4   node2   \u003cnone\u003e           \u003cnone\u003e \n1.2.3.4.5.6.7.8.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-ced8kps",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ced8kps",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "查看 Dashboard 的 NodePort 端口："
				}
			]
		},
		{
			"ID": "20221210154701-azbkemw",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-azbkemw",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl get svc -n kubernetes-dashboard \nNAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE \ndashboard-metrics-scraper   ClusterIP   10.99.37.172    \u003cnone\u003e        8000/TCP        25m \nkubernetes-dashboard        NodePort    10.103.102.27   \u003cnone\u003e        443:31050/TCP   25m \n1.2.3.4.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-d4345t3",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-d4345t3",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后可以通过上面的 31050 端口去访问 Dashboard，要记住使用 https，Chrome 不生效可以使用Firefox 测试，如果没有  Firefox 下面打不开页面，可以点击下页面中的信任证书即可："
				}
			]
		},
		{
			"ID": "20221210154701-qhxnly5",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-qhxnly5",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeImage",
					"Data": "span",
					"Children": [
						{
							"Type": "NodeBang"
						},
						{
							"Type": "NodeOpenBracket"
						},
						{
							"Type": "NodeLinkText"
						},
						{
							"Type": "NodeCloseBracket"
						},
						{
							"Type": "NodeOpenParen"
						},
						{
							"Type": "NodeLinkDest",
							"Data": "https://s3.51cto.com/oss/202109/09/fed8eabdaca6b0be16cd1577311a4000.png"
						},
						{
							"Type": "NodeCloseParen"
						}
					]
				},
				{
					"Type": "NodeTextMark",
					"TextMarkType": "a",
					"TextMarkAHref": "https://s3.51cto.com/oss/202109/09/fed8eabdaca6b0be16cd1577311a4000.png",
					"TextMarkTextContent": "https://s3.51cto.com/oss/202109/09/fed8eabdaca6b0be16cd1577311a4000.png"
				}
			]
		},
		{
			"ID": "20221210154701-sxqc6bi",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-sxqc6bi",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "信任证书"
				}
			]
		},
		{
			"ID": "20221210154701-60x6957",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-60x6957",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "信任后就可以访问到 Dashboard 的登录页面了："
				}
			]
		},
		{
			"ID": "20221210154701-e27usf3",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-e27usf3",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeImage",
					"Data": "span",
					"Children": [
						{
							"Type": "NodeBang"
						},
						{
							"Type": "NodeOpenBracket"
						},
						{
							"Type": "NodeLinkText"
						},
						{
							"Type": "NodeCloseBracket"
						},
						{
							"Type": "NodeOpenParen"
						},
						{
							"Type": "NodeLinkDest",
							"Data": "https://s5.51cto.com/oss/202109/09/847ff6952d15ff75e20dd8a195bb65f7.png"
						},
						{
							"Type": "NodeCloseParen"
						}
					]
				},
				{
					"Type": "NodeTextMark",
					"TextMarkType": "a",
					"TextMarkAHref": "https://s5.51cto.com/oss/202109/09/847ff6952d15ff75e20dd8a195bb65f7.png",
					"TextMarkTextContent": "https://s5.51cto.com/oss/202109/09/847ff6952d15ff75e20dd8a195bb65f7.png"
				}
			]
		},
		{
			"ID": "20221210154701-top9oyt",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-top9oyt",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "Dashboard 登录页面"
				}
			]
		},
		{
			"ID": "20221210154701-ewigieb",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-ewigieb",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后创建一个具有全局所有权限的用户来登录 Dashboard："
				}
			]
		},
		{
			"ID": "20221210154701-ou7l3bj",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-ou7l3bj",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "# admin.yaml \nkind: ClusterRoleBinding \napiVersion: rbac.authorization.k8s.io/v1 \nmetadata: \n  name: admin \nroleRef: \n  kind: ClusterRole \n  name: cluster-admin \n  apiGroup: rbac.authorization.k8s.io \nsubjects: \n- kind: ServiceAccount \n  name: admin \n  namespace: kubernetes-dashboard \n--- \napiVersion: v1 \nkind: ServiceAccount \nmetadata: \n  name: admin \n  namespace: kubernetes-dashboard \n1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16.17.18.19.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-2tv70rn",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-2tv70rn",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "直接创建："
				}
			]
		},
		{
			"ID": "20221210154701-yu8h7g4",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-yu8h7g4",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubectl apply -f admin.yaml \n➜  ~ kubectl get secret -n kubernetes-dashboard|grep admin-token \nadmin-token-lwmmx                  kubernetes.io/service-account-token   3         1d \n➜  ~ kubectl get secret admin-token-lwmmx -o jsonpath={.data.token} -n kubernetes-dashboard |base64 -d \n# 会生成一串很长的base64后的字符串 \n1.2.3.4.5.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		},
		{
			"ID": "20221210154701-vtm7v07",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-vtm7v07",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "然后用上面的 base64 解码后的字符串作为 token 登录 Dashboard 即可，新版本还新增了一个暗黑模式："
				}
			]
		},
		{
			"ID": "20221210154701-tb06fbe",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-tb06fbe",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeImage",
					"Data": "span",
					"Children": [
						{
							"Type": "NodeBang"
						},
						{
							"Type": "NodeOpenBracket"
						},
						{
							"Type": "NodeLinkText"
						},
						{
							"Type": "NodeCloseBracket"
						},
						{
							"Type": "NodeOpenParen"
						},
						{
							"Type": "NodeLinkDest",
							"Data": "https://s3.51cto.com/oss/202109/09/96844bd58802aaab818a42113a212c74.png"
						},
						{
							"Type": "NodeCloseParen"
						}
					]
				},
				{
					"Type": "NodeTextMark",
					"TextMarkType": "a",
					"TextMarkAHref": "https://s3.51cto.com/oss/202109/09/96844bd58802aaab818a42113a212c74.png",
					"TextMarkTextContent": "https://s3.51cto.com/oss/202109/09/96844bd58802aaab818a42113a212c74.png"
				}
			]
		},
		{
			"ID": "20221210154701-opnyj2h",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-opnyj2h",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "k8s dashboard"
				}
			]
		},
		{
			"ID": "20221210154701-0b69zwa",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-0b69zwa",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "最终我们就完成了使用 kubeadm 搭建 v1.22.1 版本的高可用 kubernetes 集群，使用  coredns、ipvs、flannel、containerd、kube-vip 这些组件。"
				}
			]
		},
		{
			"ID": "20221210154701-pbuea5f",
			"Type": "NodeHeading",
			"HeadingLevel": 3,
			"Properties": {
				"id": "20221210154701-pbuea5f",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "清理"
				}
			]
		},
		{
			"ID": "20221210154701-7n5f4uk",
			"Type": "NodeParagraph",
			"Properties": {
				"id": "20221210154701-7n5f4uk",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeText",
					"Data": "如果你的集群安装过程中遇到了其他问题，我们可以使用下面的命令来进行重置："
				}
			]
		},
		{
			"ID": "20221210154701-2ruka7p",
			"Type": "NodeCodeBlock",
			"IsFencedCodeBlock": true,
			"Properties": {
				"id": "20221210154701-2ruka7p",
				"updated": "20221210154701"
			},
			"Children": [
				{
					"Type": "NodeCodeBlockFenceOpenMarker",
					"Data": "```"
				},
				{
					"Type": "NodeCodeBlockFenceInfoMarker"
				},
				{
					"Type": "NodeCodeBlockCode",
					"Data": "➜  ~ kubeadm reset \n➜  ~ ifconfig cni0 down \u0026\u0026 ip link delete cni0 \n➜  ~ ifconfig flannel.1 down \u0026\u0026 ip link delete flannel.1 \n➜  ~ rm -rf /var/lib/cni/ \n1.2.3.4.\n"
				},
				{
					"Type": "NodeCodeBlockFenceCloseMarker",
					"Data": "```"
				}
			]
		}
	]
}